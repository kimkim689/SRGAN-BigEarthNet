{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Import model modules\n",
    "from config.config import TrainingConfig\n",
    "from models.generator import Generator\n",
    "from models.discriminator import Discriminator\n",
    "from utils.data_loader import BigEarthNetSRDataset, create_data_splits, create_dataloaders\n",
    "from utils.training import SRGANTrainer\n",
    "from utils.metrics import EvaluationMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import model architecture and metrics from SRGAN_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up configuration\n",
    "config = TrainingConfig()\n",
    "\n",
    "# Modify default parameters here\n",
    "#config.batch_size = 8\n",
    "#config.num_epochs = 100\n",
    "#config.lr_generator = 1e-4\n",
    "#config.lr_discriminator = 4e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up Dataset Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "data_dir = \"C:\\\\Users\\\\kimki\\\\Downloads\\\\SRGAN_Satellite\"  # Modify this path\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Spliting: 80% for training, 10% for validation and 10% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = BigEarthNetSRDataset(\n",
    "    root_dir=data_dir,\n",
    "    subset_size=None,  # Set a number here to use subset of data\n",
    "    augment=True\n",
    ")\n",
    "# Create splits\n",
    "train_set, val_set, test_set = create_data_splits(dataset)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_set=train_set,\n",
    "    val_set=val_set,\n",
    "    test_set=test_set,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Training samples: {len(train_set)}\")\n",
    "print(f\"Validation samples: {len(val_set)}\")\n",
    "print(f\"Test samples: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_for_display(tensor):\n",
    "    \"\"\"Normalize tensor to 0-1 range for display\"\"\"\n",
    "    min_val = tensor.min()\n",
    "    max_val = tensor.max()\n",
    "    normalized = (tensor - min_val) / (max_val - min_val + 1e-8)\n",
    "    return normalized\n",
    "\n",
    "def create_rgb_composite(tensor):\n",
    "    \"\"\"Convert single/double channel image to RGB for display\"\"\"\n",
    "    if tensor.shape[0] == 1:  # Single channel\n",
    "        return torch.cat([tensor] * 3, dim=0)\n",
    "    elif tensor.shape[0] == 2:  # Two channels\n",
    "        # Use first channel for R, second for G, and their mean for B\n",
    "        r = tensor[0:1]\n",
    "        g = tensor[1:2]\n",
    "        b = torch.mean(tensor, dim=0, keepdim=True)\n",
    "        return torch.cat([r, g, b], dim=0)\n",
    "    else:\n",
    "        return tensor[:3]  # Take first 3 channels\n",
    "\n",
    "def plot_sample(batch):\n",
    "    if batch is None:\n",
    "        print(\"Received empty batch\")\n",
    "        return\n",
    "        \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Plot 20m bands (6 channels)\n",
    "    img_20m = batch['bands_20m'][0]  # Shape: [6, 60, 60]\n",
    "    img_20m = create_rgb_composite(img_20m)  # Convert to RGB\n",
    "    img_20m = normalize_for_display(img_20m)\n",
    "    axes[0].imshow(img_20m.permute(1, 2, 0).cpu().numpy())\n",
    "    axes[0].set_title('20m Bands (First 3 channels)')\n",
    "    \n",
    "    # Plot 60m bands (2 channels)\n",
    "    img_60m = batch['bands_60m'][0]  # Shape: [2, 20, 20]\n",
    "    img_60m = create_rgb_composite(img_60m)  # Convert to RGB\n",
    "    img_60m = normalize_for_display(img_60m)\n",
    "    axes[1].imshow(img_60m.permute(1, 2, 0).cpu().numpy())\n",
    "    axes[1].set_title('60m Bands (RGB composite)')\n",
    "    \n",
    "    # Plot 10m bands (4 channels)\n",
    "    img_10m = batch['bands_10m'][0]  # Shape: [4, 120, 120]\n",
    "    img_10m = create_rgb_composite(img_10m)  # Take first 3 channels\n",
    "    img_10m = normalize_for_display(img_10m)\n",
    "    axes[2].imshow(img_10m.permute(1, 2, 0).cpu().numpy())\n",
    "    axes[2].set_title('10m Bands (First 3 channels)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print shape information\n",
    "    print(\"\\nBatch shapes:\")\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key}: {value.shape}\")\n",
    "        print(f\"Value range: [{value.min():.2f}, {value.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    if sample_batch is not None:\n",
    "        plot_sample(sample_batch)\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying sample: {str(e)}\")\n",
    "\n",
    "# Display individual bands\n",
    "def plot_individual_bands(batch):\n",
    "    \"\"\"Plot each band separately\"\"\"\n",
    "    if batch is None:\n",
    "        return\n",
    "        \n",
    "    # Plot 20m bands\n",
    "    n_bands_20m = batch['bands_20m'].shape[1]\n",
    "    fig, axes = plt.subplots(1, n_bands_20m, figsize=(20, 4))\n",
    "    for i in range(n_bands_20m):\n",
    "        img = normalize_for_display(batch['bands_20m'][0, i])\n",
    "        axes[i].imshow(img.cpu().numpy(), cmap='gray')\n",
    "        axes[i].set_title(f'20m Band {i+1}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 60m bands\n",
    "    n_bands_60m = batch['bands_60m'].shape[1]\n",
    "    fig, axes = plt.subplots(1, n_bands_60m, figsize=(8, 4))\n",
    "    for i in range(n_bands_60m):\n",
    "        img = normalize_for_display(batch['bands_60m'][0, i])\n",
    "        axes[i].imshow(img.cpu().numpy(), cmap='gray')\n",
    "        axes[i].set_title(f'60m Band {i+1}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 10m bands\n",
    "    n_bands_10m = batch['bands_10m'].shape[1]\n",
    "    fig, axes = plt.subplots(1, n_bands_10m, figsize=(16, 4))\n",
    "    for i in range(n_bands_10m):\n",
    "        img = normalize_for_display(batch['bands_10m'][0, i])\n",
    "        axes[i].imshow(img.cpu().numpy(), cmap='gray')\n",
    "        axes[i].set_title(f'10m Band {i+1}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# display the individual bands\n",
    "if sample_batch is not None:\n",
    "    plot_individual_bands(sample_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "generator = Generator(n_res_blocks=config.n_res_blocks).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Initialize plot data\n",
    "plot_data = {\n",
    "    'g_losses': [],\n",
    "    'd_losses': [],\n",
    "    'psnr': [],\n",
    "    'ssim': [],\n",
    "    'mse': []\n",
    "}\n",
    "def training_callback(epoch, train_metrics, val_metrics):\n",
    "    \"\"\"Callback function for updating plots during training\"\"\"\n",
    "    # Update plot data\n",
    "    plot_data['g_losses'].append(train_metrics['generator_losses'])\n",
    "    plot_data['d_losses'].append(train_metrics['discriminator_losses'])\n",
    "    plot_data['psnr'].append(val_metrics['PSNR'])\n",
    "    plot_data['ssim'].append(val_metrics['SSIM'])\n",
    "    plot_data['mse'].append(val_metrics['MSE'])\n",
    "    # Create figure with 2x2 subplots\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    # Subplot for Losses\n",
    "    plt.subplot(221)\n",
    "    plt.plot(plot_data['g_losses'], label='Generator')\n",
    "    plt.plot(plot_data['d_losses'], label='Discriminator')\n",
    "    plt.title('Losses')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Subplot for PSNR\n",
    "    plt.subplot(222)\n",
    "    plt.plot(plot_data['psnr'])\n",
    "    plt.title('PSNR')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('PSNR (dB)')\n",
    "    \n",
    "    # Subplot for SSIM\n",
    "    plt.subplot(223)\n",
    "    plt.plot(plot_data['ssim'])\n",
    "    plt.title('SSIM')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('SSIM Value')\n",
    "    \n",
    "    # Subplot for MSE\n",
    "    plt.subplot(224)\n",
    "    plt.plot(plot_data['mse'])\n",
    "    plt.title('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Initialize trainer\n",
    "\n",
    "trainer = SRGANTrainer(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint_path = None  # Set path to checkpoint if resuming training\n",
    "if checkpoint_path:\n",
    "    start_epoch, metrics = trainer.load_checkpoint(checkpoint_path)\n",
    "    print(f\"Resumed from epoch {start_epoch}\")\n",
    "    print(f\"Previous metrics: {metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain generator\n",
    "trainer.pretrain_generator(train_loader, num_epochs=5)\n",
    "\n",
    "# Main training with plot updates\n",
    "trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=config.num_epochs,\n",
    "    callback=training_callback\n",
    ")\n",
    "\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test final model\n",
    "print(\"Evaluating final model on test set...\")\n",
    "test_metrics = trainer._validate(test_loader)\n",
    "print(\"\\nTest Results:\")\n",
    "for metric_name, value in test_metrics.items():\n",
    "    print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "# Generate final samples\n",
    "trainer._generate_samples(test_loader, \"final_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "torch.save({\n",
    "    'generator_state_dict': generator.state_dict(),\n",
    "    'discriminator_state_dict': discriminator.state_dict(),\n",
    "    'test_metrics': test_metrics\n",
    "}, output_dir / \"final_model.pth\")\n",
    "\n",
    "# Save training history\n",
    "with open(output_dir / \"training_history.json\", 'w') as f:\n",
    "    json.dump(plot_data, f, indent=4)\n",
    "\n",
    "print(\"Training completed and results saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
